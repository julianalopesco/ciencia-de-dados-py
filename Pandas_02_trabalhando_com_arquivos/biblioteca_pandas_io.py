# -*- coding: utf-8 -*-
"""Biblioteca_pandas_io.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GkZnMNRaw2k32xE0TJGH-oUtgudBT9iY
"""

import pandas as pd

#01 - TRABALHANDO COM CSV

#carregando os dados
url = 'https://raw.githubusercontent.com/alura-cursos/pandas/main/superstore_data.csv'



#lendo os dados
dados_mercado = pd.read_csv(url)

dados_mercado.head()

#PARÂMETROS PARA A FUNÇÃO READ

#definindo as linhas a serem abertas
dados_primeiras_linhas = pd.read_csv(url,nrows=5)
dados_primeiras_linhas

#selecionando as colunas a serem mostradas
dados_selecao = pd.read_csv(url, usecols=['Id','Year_Birth','Income']) #as colunas também podem ser indicadas pela posição, iniciando por 0
dados_selecao

#salvando o arquivo
dados_selecao.to_csv('clientes_mercado.csv',index=False)

#lendo arquivos no googlecolab
pd.read_csv('/content/clientes_mercado.csv')

#02 - TRABALHANDO COM PLANILHAS

import pandas as pd

#carregando os dados
url = 'https://github.com/alura-cursos/Pandas/blob/main/emissoes_CO2.xlsx?raw=True' #raw=true: para ter acesso aos dados brutos

#lendo o arquivo
dados_co2 = pd.read_excel(url)

dados_co2.head()

#verificando se existem mais páginas na planilha
pd.ExcelFile(url).sheet_names

#parametrizando a função read
percapita = pd.read_excel(url,sheet_name='emissoes_percapita')

percapita.head()

#parametrizando o intervalo
intervalo = pd.read_excel(url, sheet_name='emissoes_C02',usecols='A:D', nrows=10)

intervalo

#salvando o arquivo em excel
percapita.to_excel('co2_percapita.xlsx',index=False)

#lendo o arquivo
pd.read_excel('/content/co2_percapita.xlsx')

#03 - TRABALHANDO COM GOOGLE PLANILHAS

#https://docs.google.com/spreadsheets/d/1V4qldR4TuLPhwQrGEouWKBRl4dXU63A_3nvxyjIk6N8/edit?usp=sharing
#separando o id da planilha
sheet_id = '1V4qldR4TuLPhwQrGEouWKBRl4dXU63A_3nvxyjIk6N8'

#parametrizando a url
url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet' #gviz: api de dataviz da google, tqx: retorno dos dados

#verificando o arquivo
dados_co2_sheets = pd.read_csv(url)

dados_co2_sheets.head()

#especificando a página
sheet_id = '1V4qldR4TuLPhwQrGEouWKBRl4dXU63A_3nvxyjIk6N8'
sheet_name = 'emissoes_percapita'
url_percapita = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'

#Visualizando o df
percapita_sheets = pd.read_csv(url_percapita)
percapita_sheets.head()

#04 MANIPULANDO ARQUIVOS JSON
import pandas as pd

#fazendo a leitura do arquivo
dados_pacientes = pd.read_json('/content/pacientes.json')

#visualizando o df
dados_pacientes

#lidando com jsons aninhados
dados_pessoas = pd.read_json('/content/pacientes_2.json')

dados_pessoas

#ajustando jsons aninhados
df_normalizado = pd.json_normalize(dados_pessoas['Pacientes'])

df_normalizado

#salvando em json
df_normalizado.to_json('historico_pacientes_normalizado.json')

pd.read_json('/content/historico_pacientes_normalizado.json')

#REQUISITANDO JSONS DE UMA API
import pandas as pd
import requests
import json

#fazendo a requisição
dados_frutas = requests.get('https://fruityvice.com/api/fruit/all')

#atribuindo a uma variavel
resultado = json.loads(dados_frutas.text)

pd.DataFrame(resultado)

#normalizando os dados
import pandas as pd
dados_frutas_normalizado = pd.json_normalize(resultado)

dados_frutas_normalizado

#04 LENDO DADOS EM HTML
import pandas as pd

#carregando dados em tabelas hmtl
dados_html = pd.read_html('/filmes_wikipedia.html') #pesquisa por trechos com a tag <table>

dados_html

type(dados_html)
len(dados_html) #verificando a quantidade de tabelas

top_filmes = dados_html[1] #a posição do df

top_filmes

#salvando o df em html
top_filmes.to_html('top_filmes.html')

#salvando em outros formatos
#top_filmes.to_csv('top_filmes_1998.csv',index=False)

# 05 LENDO DADOS EM XML

import pandas as pd

#criando a variável
dados_imdb = pd.read_xml('/content/imdb_top_1000.xml')

dados_imdb.head(3)

#salvando
dados_imdb.to_xml('filmes_imdb.xml')

#06 TRABALHANDO COM BANCOS DE DADOS

import pandas as pd
import sqlalchemy

sqlalchemy.__version__

#ajustando a versão do sqlalchemy, para ser compativel com o pandas, no prompt:
#pip install sqlalchemy==1.4.36

from sqlalchemy import create_engine, MetaData, Table, inspect

#criando o db
engine = create_engine('sqlite:///:memory:') #sqlite já é nativo no googlecolab, e será armazenado localmente

#colocando o arquivo csv dentro do banco
url = 'https://raw.githubusercontent.com/alura-cursos/Pandas/main/clientes_banco.csv'

import pandas as pd

dados = pd.read_csv(url)

dados.head()

#colocando os dados dentro do db
dados.to_sql('clientes',engine, index=False)

#inspecionando o db
inspector = inspect(engine)

#printando o nome das tabelas
print(inspector.get_table_names())

#acessando as informações

#criando a consulta
query = 'SELECT * FROM clientes WHERE Categoria_de_renda="Empregado"' #dentro das aspas a consulta em sql

#lendo a consulta
empregados = pd.read_sql(query,engine)

#lendo a tabela
empregados.to_sql('empregados',con=engine, index=False) #con: especifica o objeto engine

pd.read_sql_table('empregados',engine, columns=['ID_Cliente', 'Grau_escolaridade', 'Rendimento_anual'])

#atualizando o db

query = 'SELECT * FROM clientes'

pd.read_sql(query, engine)

query = 'DELETE FROM clientes WHERE ID_Cliente=508804'
with engine.conect() as conn: #garante que a conexão com o db seja fechada corretamente depois da consulta
  conn.execute(query)

#verificando a tabela novamente
pd.read_sql_table('clientes', engine)