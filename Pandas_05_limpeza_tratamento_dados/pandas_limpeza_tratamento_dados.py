# -*- coding: utf-8 -*-
"""pandas_limpeza_tratamento_dados.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rgAsBFcUu-ogQSYCSX3uL-1xc5T4i3pT
"""

#CONHECENDO OS DADOS
import pandas as pd

dados_churn = pd.read_json('/content/dataset-telecon.json')
dados_churn.head()

dados_churn['conta'][0]

#normalizando os dados
pd.json_normalize(dados_churn['conta']).head()

pd.json_normalize(dados_churn['telefone']).head()

#agilizando a conversão
import json

with open('/content/dataset-telecon.json') as f:
  json_bruto = json.load(f)

json_bruto

dados_normalizados = pd.json_normalize(json_bruto)
dados_normalizados.head()

dados_normalizados.info()

#transformando os dados, removendo os espacos da string

#filtrando os dados
dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '].head()

#selecionando colunas para visualizar
dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '][
    ['cliente.tempo_servico','conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']
]

#extraindo o id das linhas onde os dados serão alterados
idx = dados_normalizados[dados_normalizados['conta.cobranca.Total'] == ' '].index

dados_normalizados.loc[idx, 'conta.cobranca.Total'] = dados_normalizados.loc[idx, 'conta.cobranca.mensal'] * 24 #24 = qtde de meses

dados_normalizados.loc[idx, 'cliente.tempo_servico'] = 24

dados_normalizados.loc[idx] [
    ['cliente.tempo_servico','conta.contrato', 'conta.cobranca.mensal', 'conta.cobranca.Total']
]

#transformando os dados

dados_normalizados['conta.cobranca.Total'] = dados_normalizados['conta.cobranca.Total'].astype(float)

dados_normalizados.info()

#identificando e tratando strings vazias

#verificando os conetúdos únicos presentes nas colunas
for col in dados_normalizados.columns:
    print(f"Coluna: {col}")
    print(dados_normalizados[col].unique())
    print("-" * 30)

dados_normalizados.query("Churn == '' ")

#descartando os dados com vazio

dados_sem_vazio = dados_normalizados[dados_normalizados['Churn'] != ''].copy() #criando a cópia do df

dados_sem_vazio.info()

dados_sem_vazio.reset_index(drop=True,inplace=True) #subsituindo os index antigos por indices sequenciais

dados_sem_vazio

#identificando e tratando dados duplicados

dados_sem_vazio.duplicated()

dados_sem_vazio.duplicated().sum() #para ver a quantidade de amostras duplicadas

filtro_duplicadas = dados_sem_vazio.duplicated()
filtro_duplicadas

dados_sem_vazio[filtro_duplicadas]

dados_sem_vazio.drop_duplicates(inplace=True)

dados_sem_vazio.duplicated().sum()

#identificando e substituindo dados nulos
dados_sem_vazio.isna()

dados_sem_vazio.isna().sum()

dados_sem_vazio.isna().sum().sum() #soma o total de nulos no df

dados_sem_vazio[dados_sem_vazio.isna().any(axis=1)] #amostras com pelo menos 1 valor nulo em alguma das colunas

filtro = dados_sem_vazio['cliente.tempo_servico'].isna()

dados_sem_vazio[filtro][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']] #colunas com nulos

#calculando o valor faltante e aplicando nas células nulas

import numpy as np
dados_sem_vazio['cliente.tempo_servico'].fillna( #aplica a coluna onde tem nulos
    np.ceil( #arredonda pra cima o valor
       dados_sem_vazio['conta.cobranca.Total'] / dados_sem_vazio['conta.cobranca.mensal']
    ), inplace=True
)

#verificando o resultado
dados_sem_vazio[filtro][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']]

dados_sem_vazio.isna().sum()

#verificando o valor mais frequente na col
dados_sem_vazio['conta.contrato'].value_counts

#retirando as amostras com dados nulos
colunas_dropar = ['conta.contrato', 'conta.faturamente_eletronico', 'conta.metodo_pagamento']

dados_sem_vazio[colunas_dropar].isna().any(axis=1).sum #retorna qtde para as colunas mostrando onde tem dados nulos

#excluindo registros com dados nulos
df_sem_nulo = dados_sem_vazio.dropna(subset=colunas_dropar).copy()
df_sem_nulo.head()

#resetando o index
df_sem_nulo.reset_index(drop=True,inplace=True)

df_sem_nulo.isna().sum()

#LIDANDO COM OUTLIERS
df_sem_nulo.describe() #verificando os outliers (25%, 75%)

#usando o bloxplot para visualizar os outliers
import seaborn as sns

sns.boxplot(x=df_sem_nulo['cliente.tempo_servico'])

#identificando os outliers com a teoria de box-plot

Q1 = df_sem_nulo['cliente.tempo_servico'].quantile(.25)
Q3 = df_sem_nulo['cliente.tempo_servico'].quantile(.75)
IQR = Q3 - Q1 #intervalo interquartil
limite_inferior = Q1 - 1.5*IQR
limite_superior = Q3 + 1.5*IQR

#filtrando o conjunto de dados
outliers_index = (df_sem_nulo['cliente.tempo_servico'] < limite_inferior) | (df_sem_nulo['cliente.tempo_servico'] > limite_superior) #| = ou

df_sem_nulo[outliers_index]['cliente.tempo_servico'] #visualizando os outliers

#substituindo valores para os outliers
df_sem_out = df_sem_nulo.copy()

df_sem_out[outliers_index]['cliente.tempo_servico'] #fazendo o filtro para conferir o df

#usando os dados de uma col pra achar os valores de outras
df_sem_out.loc[outliers_index, 'cliente.tempo_servico'] = np.ceil(
    df_sem_out.loc[outliers_index, 'conta.cobranca.Total'] /
    df_sem_out.loc[outliers_index, 'conta.cobranca.mensal']
)

#verificando se ainda existem outliers

sns.boxplot(x=df_sem_out['cliente.tempo_servico'])

#analisando os outliers que ainda sobraram
df_sem_out[outliers_index][['cliente.tempo_servico', 'conta.cobranca.mensal', 'conta.cobranca.Total']]

#removendo outliers

#refazendo o filtro
Q1 = df_sem_out['cliente.tempo_servico'].quantile(.25)
Q3 = df_sem_out['cliente.tempo_servico'].quantile(.75)
IQR = Q3 - Q1 #intervalo interquartil
limite_inferior = Q1 - 1.5*IQR
limite_superior = Q3 + 1.5*IQR

outliers_index =  (df_sem_out['cliente.tempo_servico'] < limite_inferior) |  (df_sem_out['cliente.tempo_servico'] > limite_superior)
outliers_index

df_sem_out[outliers_index]

#descartando as amostras

df_sem_out  = df_sem_out[~outliers_index] #obtem todas as amostras, menos as com ~
df_sem_out

sns.boxplot(x=df_sem_out['cliente.tempo_servico'])

#resetando o index

df_sem_out.reset_index(drop=True, inplace=True)

#TRABALHANDO COM VARIAVEIS CATEGORICAS

#substituindo valores

df_sem_id = df_sem_out.drop('id_cliente', axis=1).copy()
df_sem_id

#substituindo variaveis binárias por valores binaveis

mapeamento = {
    'nao': 0,
    'sim': 1,
    'masculino': 0,
    'feminino': 1
}

#verificando os conetúdos únicos presentes nas colunas
for col in df_sem_id.columns:
    print(f"Coluna: {col}")
    print(df_sem_id[col].unique())
    print("-" * 30)

#definindo as colunas que serão mapeadas
colunas = ['telefone.servico_telefone', 'Churn', 'cliente.parceiro', 'cliente.dependentes', 'conta.faturamente_eletronico', 'cliente.genero']

#fazendo o mapeamento
df_sem_id[colunas] = df_sem_id[colunas].replace(mapeamento)
df_sem_id

#verificando os conetúdos únicos presentes nas colunas
for col in df_sem_id.columns:
    print(f"Coluna: {col}")
    print(df_sem_id[col].unique())
    print("-" * 30)

#TRABALHANDO COM AS VARIAVEIS CATEGORICAS NÃO BINÁRIAS

#aplicando o one hot encoder/dummy
s= pd.Series(list('abca'))
s

pd.get_dummies(s)

#aplicando o dummies no projeto
df_sem_id.info()

df_dummies = pd.get_dummies(df_sem_id).copy() #cria uma col pra cada categoria distinta da coluna #,dtype=int: caso a versão do pandas exiba o resultado como true or false
df_dummies.head()

#visualizando as col criadas
df_dummies.columns

df_dummies.info()

